import json
from pathlib import Path
from datetime import datetime
from loguru import logger

# Import our scraper components
from scraper.rijlessen_nl_scraper import RijlessenNLScraper
from scraper.base_scraper import ScrapedSchool

# Configure logging
logger.add("logs/test_scraper_{time:YYYY-MM-DD}.log", rotation="500 MB", level="INFO")

def test_scraper_basic():
    """Test the scraper with a small number of cities."""
    print("ğŸš€ TESTING DRIVING SCHOOL SCRAPER")
    print("=" * 50)
    
    # Create output directories
    Path("data").mkdir(exist_ok=True)
    Path("logs").mkdir(exist_ok=True)
    
    # Initialize scraper
    scraper = RijlessenNLScraper()
    
    print("ğŸ“¡ Starting test scrape (limited to 3 cities)...")
    
    try:
        # Test with just 3 cities
        schools = scraper.scrape(max_cities=3)
        
        print(f"\nâœ… Scraping completed!")
        print(f"ğŸ“Š Found {len(schools)} schools")
        
        if schools:
            # Save to JSON for viewing
            timestamp = datetime.utcnow().strftime("%Y%m%d_%H%M%S")
            filename = f"test_schools_{timestamp}.json"
            output_path = Path("data") / filename
            
            # Convert to dictionaries
            school_dicts = [school.__dict__ for school in schools]
            
            with open(output_path, 'w', encoding='utf-8') as f:
                json.dump(school_dicts, f, indent=2, default=str)
            
            print(f"ğŸ’¾ Saved results to: {output_path}")
            
            # Show sample results
            print(f"\nğŸ“‹ SAMPLE RESULTS:")
            print("-" * 30)
            for i, school in enumerate(schools[:3], 1):
                print(f"\n{i}. {school.name}")
                print(f"   ğŸ“ Address: {school.address or 'N/A'}")
                print(f"   ğŸ“ Phone: {school.phone or 'N/A'}")
                print(f"   â­ Rating: {school.rating or 'N/A'}")
                print(f"   ğŸŒ Website: {school.website or 'N/A'}")
                print(f"   ğŸ”— URL: {school.url or 'N/A'}")
            
            return True
        else:
            print("âŒ No schools were found")
            return False
            
    except Exception as e:
        print(f"âŒ Error during scraping: {e}")
        logger.error(f"Scraping error: {e}", exc_info=True)
        return False

if __name__ == "__main__":
    success = test_scraper_basic()
    
    if success:
        print(f"\nğŸ‰ Test completed successfully!")
        print(f"ğŸ’¡ Run 'python viewer.py' to see detailed results")
    else:
        print(f"\nâŒ Test failed. Check logs for details.")
